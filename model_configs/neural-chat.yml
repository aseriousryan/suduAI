model_type: llama-cpp
model: neural-chat:7b-v3.1-fp16
model_path: models/neural-chat-7b-v3-1.Q5_K_M.gguf
context_length: 2048
max_tokens: 2048
temperature: 0.0
n_gpu_layers: 35
stop: []
last_n_tokens: 2048
prompt_template: "### System:
{system_message}

### User:
{prompt}

### Assistant:"

prefix_template: "### System:
{prefix_text}

"

suffix_template: "### User:
{suffix_text}

### Assistant:"
